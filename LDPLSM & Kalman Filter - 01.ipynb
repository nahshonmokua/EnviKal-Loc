{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93837f51-211a-46d8-bdc0-0b9173590809",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;\">\n",
    "LoRaWAN Indoor Distance estimation via Log-Distance Path Loss & Shadow Modeling: Kalman Filtering and MLR\n",
    "</p>\n",
    "\n",
    "# Overview\n",
    "\n",
    "This notebook presents an end-to-end framework for enhancing wireless localization through advanced signal processing and propagation modeling. We tackle the inherent noise in Received Signal Strength Indicator (RSSI) measurements by applying a one-dimensional [Kalman filter](https://ani.stat.fsu.edu/~jfrade/HOMEWORKS/STA5107/presentation/sta5107-present/Kalman%20Filter/papers/kalman.pdf) — a recursive Bayesian estimator introduced by Kalman (1960). The filtered RSSI values are then used to calibrate robust [COST231](https://op.europa.eu/en/publication-detail/-/publication/f2f42003-4028-4496-af95-beaa38fd475f) path loss models that account for both structural and environmental influences on signal propagation.\n",
    "\n",
    "**Key components of this notebook include:**\n",
    "\n",
    "- **Data Preprocessing & Visualization:**  \n",
    "  We load a comprehensive dataset of sensor measurements, perform an 80-20 stratified train-test split, and visualize the effect of Kalman filtering on RSSI data across multiple devices.\n",
    "\n",
    "- **Kalman Filtering:**  \n",
    "  A detailed cell implements the Kalman filter using the `pykalman` library. The full state-space equations are:\n",
    "  \n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  x_{k} &= x_{k-1} + w_{k}, \\quad w_{k} \\sim \\mathcal{N}(0, Q), \\\\\n",
    "  z_{k} &= x_{k} + v_{k}, \\quad v_{k} \\sim \\mathcal{N}(0, R),\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  \n",
    "  where $x_k$ represents the latent RSSI and $z_k$ is the observed signal.\n",
    "\n",
    "- **Path Loss Modeling & Distance Estimation:**  \n",
    "  We extend the classical log-distance equation under the COST231 model for a single-floor scenario by incorporating wall losses as a summation over categorical wall types. The extended model is:\n",
    "\n",
    "  $$\n",
    "  PL(d) = PL(d_0) + 10\\,n\\,\\log_{10}\\!\\left(\\frac{d}{d_0}\\right) + \\sum_{i=1}^{K} W_i\\,L_i + \\epsilon,\n",
    "  $$\n",
    "\n",
    "  where:\n",
    "  - $PL(d_0)$ is the reference path loss at a close-in distance $d_0$,\n",
    "  - $n$ is the path loss exponent,\n",
    "  - $d$ is the distance,\n",
    "  - $K$ is the total number of distinct wall categories (e.g., concrete, wooden),\n",
    "  - $W_i$ is the count of walls of type $i$,\n",
    "  - $L_i$ is the attenuation factor for wall type $i$, and\n",
    "  - $\\epsilon$ captures the random shadowing effects.\n",
    "\n",
    "  \n",
    "  which is later extended to incorporate additional dynamic environmental parameters (e.g., temperature, humidity, etc.).\n",
    "\n",
    "- **Model Evaluation & Visualization:**  \n",
    "  Finally, we compare model performance (using metrics such as RMSE, $R^2$, and the standard deviation of shadowing) across raw and filtered RSSI inputs. Visualizations include scatter plots, histograms, and cumulative distribution functions (CDFs) to assess the models' predictive capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1a26bc-2f74-4efc-909d-4117db00b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pykalman import KalmanFilter\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.optimize import curve_fit \n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb4b142-bbab-4394-bb66-be01d960b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 882108 entries, 0 to 882107\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count   Dtype              \n",
      "---  ------       --------------   -----              \n",
      " 0   time         882108 non-null  datetime64[ns, UTC]\n",
      " 1   device_id    882108 non-null  object             \n",
      " 2   co2          882108 non-null  float64            \n",
      " 3   humidity     882108 non-null  float64            \n",
      " 4   pm25         882108 non-null  float64            \n",
      " 5   pressure     882108 non-null  float64            \n",
      " 6   temperature  882108 non-null  float64            \n",
      " 7   rssi         882108 non-null  float64            \n",
      " 8   snr          882108 non-null  float64            \n",
      " 9   SF           882108 non-null  int64              \n",
      " 10  frequency    882108 non-null  float64            \n",
      " 11  f_count      882108 non-null  float64            \n",
      " 12  p_count      882108 non-null  float64            \n",
      " 13  toa          882108 non-null  float64            \n",
      " 14  distance     882108 non-null  int64              \n",
      " 15  c_walls      882108 non-null  int64              \n",
      " 16  w_walls      882108 non-null  int64              \n",
      " 17  exp_pl       882108 non-null  float64            \n",
      " 18  n_power      882108 non-null  float64            \n",
      " 19  esp          882108 non-null  float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(14), int64(4), object(1)\n",
      "memory usage: 134.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load data and convert time column\n",
    "df = pd.read_csv('../all_data_files/cleaned_dataset_per_device.csv')\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2e4b28-3ece-48c9-bd08-9072be2cbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80-20 stratified train-test split ensuring all 6 devices are included in both sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['device_id'], random_state=200)\n",
    "\n",
    "# Sort by time for clarity in plotting\n",
    "train_df = train_df.sort_values('time')\n",
    "test_df = test_df.sort_values('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678a4b4-cece-4846-891c-f568faf524ed",
   "metadata": {},
   "source": [
    "### Introduction to Kalman Filtering\n",
    "\n",
    "Kalman filtering provides an optimal estimation framework for linear systems corrupted by Gaussian noise.\n",
    "The filter recursively computes the predicted state and its uncertainty, then updates these estimates with new observations through:\n",
    "\n",
    "$$\n",
    "K_k = \\frac{P_{k|k-1}}{P_{k|k-1} + R}, \\quad \\hat{x}_k = \\hat{x}_{k|k-1} + K_k (z_k - \\hat{x}_{k|k-1})\n",
    "$$\n",
    "\n",
    "where $K_k$ is the Kalman gain and $P_{k|k-1}$ is the predicted covariance. This methodology mitigates transient measurement anomalies and refines the quality of the RSSI input for subsequent modeling tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25af4b0-109c-4abf-8d11-6f952b6b935d",
   "metadata": {},
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.utils import use_named_args\n",
    "\n",
    "# Define search space\n",
    "space = [Real(0.001, 0.1, name='Q'), Real(0.1, 2.0, name='R')]\n",
    "\n",
    "# Objective function: Minimize RSSI std dev after filtering\n",
    "@use_named_args(space)\n",
    "def kalman_objective(Q, R):\n",
    "    kf = KalmanFilter(\n",
    "        initial_state_mean=train_df['rssi'].iloc[0],\n",
    "        transition_covariance=Q,\n",
    "        observation_covariance=R\n",
    "    )\n",
    "    filtered_rssi = kf.smooth(train_df['rssi'].values)[0].flatten()\n",
    "    return np.std(filtered_rssi)\n",
    "\n",
    "# Run optimization\n",
    "res = gp_minimize(kalman_objective, space, n_calls=50, random_state=0)\n",
    "print(f\"Optimal Q: {res.x[0]:.4f}, R: {res.x[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcb3687-f0a5-46d6-b40a-453705f769f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Kalman filter function and apply it separately on train and test sets per device\n",
    "def kalman_filter_rssi(rssi_measurements):\n",
    "    \"\"\"\n",
    "    Applies a simple 1D Kalman filter (random-walk model) to RSSI measurements.\n",
    "    \"\"\"\n",
    "    kf = KalmanFilter(\n",
    "        initial_state_mean=rssi_measurements[0],\n",
    "       # observation_covariance=0.5,\n",
    "        observation_covariance=2.0,\n",
    "        transition_covariance=0.01\n",
    "    )\n",
    "    # kf.smooth returns (smoothed_state_means, smoothed_state_covariances)\n",
    "    return kf.smooth(rssi_measurements)[0].flatten()\n",
    "\n",
    "# Apply Kalman filter on training data per device\n",
    "train_df['filtered_rssi'] = train_df.groupby('device_id')['rssi'].transform(\n",
    "    lambda x: kalman_filter_rssi(x.values)\n",
    ")\n",
    "# Compute exp_pl_filtered for training data using: \n",
    "                    # exp_pl_filtered = 14 - 0.14 + 0.4 + 3 - filtered_rssi\n",
    "                    # From: tx_p=14, tx_cl=0.14, tx_ag=0.4, rx_ag=3, tx_cl=0\n",
    "train_df['exp_pl_filtered'] = 14 - 0.14 + 0.4 + 3 - train_df['filtered_rssi']\n",
    "\n",
    "# Apply Kalman filter on test data per device (separately)\n",
    "test_df['filtered_rssi'] = test_df.groupby('device_id')['rssi'].transform(\n",
    "    lambda x: kalman_filter_rssi(x.values)\n",
    ")\n",
    "\n",
    "# Compute exp_pl_filtered for test data\n",
    "test_df['exp_pl_filtered'] = 14 - 0.14 + 0.4 + 3 - test_df['filtered_rssi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8346d315-d109-4ac9-b8e4-ea30bfb1c48a",
   "metadata": {},
   "source": [
    "### Kalman Filter Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baebce8f-030f-41ee-8511-84ca54571eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of raw RSSI per device\n",
    "raw_std = train_df.groupby('device_id')['rssi'].std()\n",
    "\n",
    "# Calculate the standard deviation of filtered RSSI per device\n",
    "filtered_std = train_df.groupby('device_id')['filtered_rssi'].std()\n",
    "\n",
    "# Combine the results into a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Raw_Std (dB)': raw_std,\n",
    "    'Filtered_Std (dB)': filtered_std\n",
    "})\n",
    "\n",
    "# Compute the percentage reduction in standard deviation per device\n",
    "results_df['Reduction_Percentage (%)'] = ((results_df['Raw_Std (dB)'] - results_df['Filtered_Std (dB)']) /\n",
    "                                            results_df['Raw_Std (dB)']) * 100\n",
    "\n",
    "# Display the DataFrame with the results\n",
    "print(\"\\nReduction in RSSI standard deviation per device:\\n\")\n",
    "display(results_df)\n",
    "\n",
    "# Calculate overall averages\n",
    "average_raw_std = results_df['Raw_Std (dB)'].mean()\n",
    "average_filtered_std = results_df['Filtered_Std (dB)'].mean()\n",
    "average_reduction = results_df['Reduction_Percentage (%)'].mean()\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nSummary:\")\n",
    "print(\"Average Raw RSSI Std Dev: {:.2f} dB\".format(average_raw_std))\n",
    "print(\"Average Filtered RSSI Std Dev: {:.2f} dB\".format(average_filtered_std))\n",
    "print(\"Overall Average Reduction: {:.2f}%\".format(average_reduction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb586c6-dc40-4425-96ef-afb8dd3b11a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot train data (Real vs. Filtered RSSI) for each device\n",
    "device_ids = train_df['device_id'].unique()\n",
    "num_devices = len(device_ids)\n",
    "fig, axes = plt.subplots(nrows=num_devices, ncols=1, figsize=(12, 3*num_devices), sharex=True)\n",
    "if num_devices == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, device in zip(axes, device_ids):\n",
    "    device_data = train_df[train_df['device_id'] == device].sort_values('time')\n",
    "    ax.plot(device_data['time'], device_data['rssi'], label='Real RSSI', alpha=0.6)\n",
    "    ax.plot(device_data['time'], device_data['filtered_rssi'], label='Filtered RSSI', alpha=0.9)\n",
    "    ax.set_title(f'Device: {device}')\n",
    "    ax.set_ylabel('RSSI')\n",
    "    ax.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769f82a-f179-4bd2-a7c6-852cd57a828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train data (Real vs. Filtered RSSI) for each device\n",
    "device_ids = train_df['device_id'].unique()\n",
    "num_devices = len(device_ids)\n",
    "fig, axes = plt.subplots(nrows=num_devices, ncols=1, figsize=(12, 3*num_devices), sharex=True)\n",
    "if num_devices == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, device in zip(axes, device_ids):\n",
    "    device_data = train_df[train_df['device_id'] == device].sort_values('time')\n",
    "    ax.plot(device_data['time'], device_data['rssi'], label='Real RSSI', alpha=0.6)\n",
    "    ax.plot(device_data['time'], device_data['filtered_rssi'], label='Filtered RSSI', alpha=0.9)\n",
    "    ax.set_title(f'Device: {device}')\n",
    "    ax.set_ylabel('RSSI')\n",
    "    ax.legend()\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c61c4e-9e7c-4798-9a77-58186bf35e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'time' column is in datetime format\n",
    "train_df['time'] = pd.to_datetime(train_df['time'])\n",
    "\n",
    "# Define the one-day segment (December 20, 2024)\n",
    "segment_start = '2024-12-20 00:00:00'\n",
    "segment_end   = '2024-12-20 23:59:59'\n",
    "train_df_segment = train_df[\n",
    "    (train_df['time'] >= segment_start) & \n",
    "    (train_df['time'] <= segment_end)\n",
    "]\n",
    "\n",
    "# Device mapping: original ID to display name\n",
    "device_map = {\n",
    "    'ED0': 'EN1',\n",
    "    'ED1': 'EN2',\n",
    "    'ED2': 'EN3',\n",
    "    'ED3': 'EN4',\n",
    "    'ED4': 'EN5',\n",
    "    'ED5': 'EN6'\n",
    "}\n",
    "\n",
    "# Get unique device IDs in ascending order\n",
    "device_ids = sorted(train_df_segment['device_id'].unique())\n",
    "num_devices = len(device_ids)\n",
    "\n",
    "# Create subplots for each device\n",
    "fig, axes = plt.subplots(nrows=num_devices, ncols=1, figsize=(6, 1 * num_devices), sharex=True)\n",
    "if num_devices == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "# Define the highlight window (9 AM to 4 PM)\n",
    "highlight_start = pd.to_datetime('2024-12-20 07:00:00')\n",
    "highlight_end   = pd.to_datetime('2024-12-20 16:00:00')\n",
    "\n",
    "for ax, device in zip(axes, device_ids):\n",
    "    device_data = train_df_segment[train_df_segment['device_id'] == device].sort_values('time')\n",
    "    \n",
    "    # Plot real vs. filtered RSSI\n",
    "    ax.plot(device_data['time'], device_data['rssi'], label='Measured RSSI', alpha=0.6)\n",
    "    ax.plot(device_data['time'], device_data['filtered_rssi'], label='Filtered RSSI', alpha=0.9)\n",
    "    \n",
    "    # Highlight 9 AM to 4 PM with a translucent rectangle\n",
    "    ax.axvspan(highlight_start, highlight_end, color='green', alpha=0.1)\n",
    "    # Add dotted lines on the left and right edges of the highlight\n",
    "    ax.axvline(highlight_start, color='green', linestyle=':', linewidth=1)\n",
    "    ax.axvline(highlight_end, color='green', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Add device name annotation (bottom left) using our mapping\n",
    "    device_label = device_map.get(device, device)\n",
    "    ax.text(0.01, 0.01, device_label, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='bottom', horizontalalignment='left')\n",
    "    \n",
    "    ax.set_ylabel('RSSI')\n",
    "    # Place legend in the bottom right corner\n",
    "    ax.legend(loc='lower right')\n",
    "    # Reduce the number of time ticks to 4 for clarity\n",
    "    ax.xaxis.set_major_locator(ticker.MaxNLocator(4))\n",
    "    # Optional: format x-axis labels nicely for datetimes\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.tight_layout(h_pad=0.5)  # Reduced gap between plots\n",
    "\n",
    "# Save the figure at high resolution\n",
    "plt.savefig('../all_data_files/Localization/Real_vs_FilteredRSSI_over_shortTime.png', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9a16f-4699-4242-a985-7f6d12e643d3",
   "metadata": {},
   "source": [
    "# Log-Distance Path Loss & Shadowing Modeling\n",
    "\n",
    "We adopt the following two models:\n",
    "\n",
    "1. **LDPLM-MW (Structural Model):**\n",
    "\n",
    "$$\n",
    "PL(d) = PL(d_0) + 10\\,n\\,\\log_{10}\\!\\left(\\frac{d}{d_0}\\right) + \\sum_{i=1}^{2} W_i\\,L_i + \\epsilon,\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $PL(d_0)$ is the reference path loss,\n",
    "- $n$ is the path loss exponent,\n",
    "- $d$ is the distance,\n",
    "- $W_1 = c_{walls}$ and $W_2 = w_{walls}$ are the counts of two wall types,\n",
    "- $L_1 = L_c$ and $L_2 = L_w$ are their corresponding attenuation factors, and\n",
    "- $\\epsilon$ captures random shadowing effects.\n",
    "\n",
    "2. **LDPLM-MW-EP (Extended Model with Environmental Parameters):**\n",
    "\n",
    "$$\n",
    "PL(d) = PL(d_0) + 10\\,n\\,\\log_{10}\\!\\left(\\frac{d}{d_0}\\right) + 20\\,\\log_{10}(f) + \\sum_{i=1}^{2} W_i\\,L_i + \\sum_{j=1}^{5} \\theta_j\\,E_j + k_{snr}\\,snr + \\epsilon,\n",
    "$$\n",
    "\n",
    "where, in addition to the parameters above:\n",
    "- $f$ is the frequency,\n",
    "- $20\\,\\log_{10}(f)$ accounts for frequency-dependent loss,\n",
    "- $\\{E_j\\}_{j=1}^{5}$ are five environmental variables (e.g., CO$_2$, humidity, PM2.5, pressure, temperature) with corresponding coefficients $\\{\\theta_j\\}$,\n",
    "- $snr$ is the signal-to-noise ratio with coefficient $k_{snr}$.\n",
    "\n",
    "These models form the basis of our analysis and are implemented as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179588a9-0cd4-4eb3-aaa5-f0a146737310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extraction & Model Function Definitions\n",
    "features = ['distance', 'frequency', 'c_walls', 'w_walls', 'co2', \n",
    "            'humidity', 'pm25', 'pressure', 'temperature', 'snr']\n",
    "X_train = np.column_stack([train_df[feat].values for feat in features])\n",
    "X_test  = np.column_stack([test_df[feat].values for feat in features])\n",
    "\n",
    "# Targets: raw and filtered exp_pl\n",
    "y_train_raw  = train_df['exp_pl'].values\n",
    "y_test_raw   = test_df['exp_pl'].values\n",
    "y_train_filt = train_df['exp_pl_filtered'].values\n",
    "y_test_filt  = test_df['exp_pl_filtered'].values\n",
    "\n",
    "# LDPLM-MW: using distance, c_walls, w_walls (indices 0,2,3)\n",
    "def log_distance_path_loss_separate_walls(x, PL_d0, n, L_c, L_w):\n",
    "    d, c_walls, w_walls = x\n",
    "    d0 = 1\n",
    "    return PL_d0 + 10 * n * np.log10(d/d0) + c_walls * L_c + w_walls * L_w\n",
    "\n",
    "# LDPLM-MW-EP: using all 10 features\n",
    "def log_distance_path_loss_with_env_params(x, PL_d0, n, L_c, L_w, a_co2, a_hum, a_pm25, a_pres, a_temp, k_snr):\n",
    "    d, freq, c_walls, w_walls, co2, hum, pm25, pres, temp, snr = x\n",
    "    d0 = 1\n",
    "    return (PL_d0 + 10 * n * np.log10(d/d0) + 20*np.log10(freq) +\n",
    "            c_walls * L_c + w_walls * L_w +\n",
    "            a_co2 * co2 + a_hum * hum + a_pm25 * pm25 +\n",
    "            a_pres * pres + a_temp * temp + snr * k_snr)\n",
    "\n",
    "idx_mw = [0, 2, 3]\n",
    "idx_ep = list(range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76341228-5a0d-4e36-b65d-f37050bf5082",
   "metadata": {},
   "source": [
    "### Model Fitting & Evaluation (Raw and Filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9712cca2-53c4-4469-b257-c31e2253caa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guesses\n",
    "initial_guess_mw = [30, 2, 5, 3]\n",
    "initial_guess_ep = [30, 2, 5, 3, 0.01, 0.01, 0.01, 0.01, 0.01, 1]\n",
    "\n",
    "# --- Fit on Raw exp_pl ---\n",
    "popt_mw_raw, _ = curve_fit(\n",
    "    log_distance_path_loss_separate_walls,\n",
    "    X_train[:, idx_mw].T, y_train_raw, p0=initial_guess_mw, maxfev=100000)\n",
    "popt_ep_raw, _ = curve_fit(\n",
    "    log_distance_path_loss_with_env_params,\n",
    "    X_train[:, idx_ep].T, y_train_raw, p0=initial_guess_ep, maxfev=100000)\n",
    "\n",
    "# --- Fit on Filtered exp_pl ---\n",
    "popt_mw_filt, _ = curve_fit(\n",
    "    log_distance_path_loss_separate_walls,\n",
    "    X_train[:, idx_mw].T, y_train_filt, p0=initial_guess_mw, maxfev=100000)\n",
    "popt_ep_filt, _ = curve_fit(\n",
    "    log_distance_path_loss_with_env_params,\n",
    "    X_train[:, idx_ep].T, y_train_filt, p0=initial_guess_ep, maxfev=100000)\n",
    "\n",
    "# --- Predictions ---\n",
    "# Raw models\n",
    "y_pred_mw_raw   = log_distance_path_loss_separate_walls(X_test[:, idx_mw].T, *popt_mw_raw)\n",
    "y_pred_ep_raw   = log_distance_path_loss_with_env_params(X_test[:, idx_ep].T, *popt_ep_raw)\n",
    "y_train_pred_mw_raw = log_distance_path_loss_separate_walls(X_train[:, idx_mw].T, *popt_mw_raw)\n",
    "y_train_pred_ep_raw = log_distance_path_loss_with_env_params(X_train[:, idx_ep].T, *popt_ep_raw)\n",
    "# Filtered models\n",
    "y_pred_mw_filt  = log_distance_path_loss_separate_walls(X_test[:, idx_mw].T, *popt_mw_filt)\n",
    "y_pred_ep_filt  = log_distance_path_loss_with_env_params(X_test[:, idx_ep].T, *popt_ep_filt)\n",
    "y_train_pred_mw_filt = log_distance_path_loss_separate_walls(X_train[:, idx_mw].T, *popt_mw_filt)\n",
    "y_train_pred_ep_filt = log_distance_path_loss_with_env_params(X_train[:, idx_ep].T, *popt_ep_filt)\n",
    "\n",
    "# --- Shadowing (train) & Metrics ---\n",
    "shadowing_mw_raw  = y_train_raw - y_train_pred_mw_raw\n",
    "sigma_mw_raw      = np.std(shadowing_mw_raw)\n",
    "shadowing_ep_raw  = y_train_raw - y_train_pred_ep_raw\n",
    "sigma_ep_raw      = np.std(shadowing_ep_raw)\n",
    "shadowing_mw_filt = y_train_filt - y_train_pred_mw_filt\n",
    "sigma_mw_filt     = np.std(shadowing_mw_filt)\n",
    "shadowing_ep_filt = y_train_filt - y_train_pred_ep_filt\n",
    "sigma_ep_filt     = np.std(shadowing_ep_filt)\n",
    "\n",
    "# Test metrics\n",
    "rmse_mw_raw_test  = np.sqrt(mean_squared_error(y_test_raw, y_pred_mw_raw))\n",
    "r2_mw_raw_test    = r2_score(y_test_raw, y_pred_mw_raw)\n",
    "rmse_ep_raw_test  = np.sqrt(mean_squared_error(y_test_raw, y_pred_ep_raw))\n",
    "r2_ep_raw_test    = r2_score(y_test_raw, y_pred_ep_raw)\n",
    "rmse_mw_filt_test = np.sqrt(mean_squared_error(y_test_filt, y_pred_mw_filt))\n",
    "r2_mw_filt_test   = r2_score(y_test_filt, y_pred_mw_filt)\n",
    "rmse_ep_filt_test = np.sqrt(mean_squared_error(y_test_filt, y_pred_ep_filt))\n",
    "r2_ep_filt_test   = r2_score(y_test_filt, y_pred_ep_filt)\n",
    "\n",
    "# Train metrics\n",
    "rmse_mw_raw_train  = np.sqrt(mean_squared_error(y_train_raw, y_train_pred_mw_raw))\n",
    "r2_mw_raw_train    = r2_score(y_train_raw, y_train_pred_mw_raw)\n",
    "rmse_ep_raw_train  = np.sqrt(mean_squared_error(y_train_raw, y_train_pred_ep_raw))\n",
    "r2_ep_raw_train    = r2_score(y_train_raw, y_train_pred_ep_raw)\n",
    "rmse_mw_filt_train = np.sqrt(mean_squared_error(y_train_filt, y_train_pred_mw_filt))\n",
    "r2_mw_filt_train   = r2_score(y_train_filt, y_train_pred_mw_filt)\n",
    "rmse_ep_filt_train = np.sqrt(mean_squared_error(y_train_filt, y_train_pred_ep_filt))\n",
    "r2_ep_filt_train   = r2_score(y_train_filt, y_train_pred_ep_filt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f73da-d275-4e83-a40d-deca04fee924",
   "metadata": {},
   "source": [
    "### Parameter & Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0d684-7493-46f7-b37a-25ebae368856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parameters from curve fitting\n",
    "params_mw_raw  = {'PL(d0)': popt_mw_raw[0], 'n': popt_mw_raw[1], 'L_c': popt_mw_raw[2], 'L_w': popt_mw_raw[3]}\n",
    "params_ep_raw  = {'PL(d0)': popt_ep_raw[0], 'n': popt_ep_raw[1], 'L_c': popt_ep_raw[2], 'L_w': popt_ep_raw[3],\n",
    "                  'a_co2': popt_ep_raw[4], 'a_hum': popt_ep_raw[5], 'a_pm25': popt_ep_raw[6],\n",
    "                  'a_pres': popt_ep_raw[7], 'a_temp': popt_ep_raw[8], 'k_snr': popt_ep_raw[9]}\n",
    "params_mw_filt = {'PL(d0)': popt_mw_filt[0], 'n': popt_mw_filt[1], 'L_c': popt_mw_filt[2], 'L_w': popt_mw_filt[3]}\n",
    "params_ep_filt = {'PL(d0)': popt_ep_filt[0], 'n': popt_ep_filt[1], 'L_c': popt_ep_filt[2], 'L_w': popt_ep_filt[3],\n",
    "                  'a_co2': popt_ep_filt[4], 'a_hum': popt_ep_filt[5], 'a_pm25': popt_ep_filt[6],\n",
    "                  'a_pres': popt_ep_filt[7], 'a_temp': popt_ep_filt[8], 'k_snr': popt_ep_filt[9]}\n",
    "\n",
    "# Build table of parameters for all 4 models\n",
    "shared_params = ['PL(d0)', 'n', 'L_c', 'L_w']\n",
    "unique_params = ['a_co2', 'a_hum', 'a_pm25', 'a_pres', 'a_temp', 'k_snr']\n",
    "parameter_list = shared_params + unique_params\n",
    "\n",
    "ldplm_mw_raw_vals  = [params_mw_raw.get(p, '-') for p in parameter_list]\n",
    "ldplm_ep_raw_vals  = [params_ep_raw.get(p, '-') for p in parameter_list]\n",
    "ldplm_mw_filt_vals = [params_mw_filt.get(p, '-') for p in parameter_list]\n",
    "ldplm_ep_filt_vals = [params_ep_filt.get(p, '-') for p in parameter_list]\n",
    "\n",
    "params_comp_df = pd.DataFrame({\n",
    "    'LDPLM-MW (raw)': ldplm_mw_raw_vals,\n",
    "    'LDPLM-MW (filt)': ldplm_mw_filt_vals,\n",
    "    'LDPLM-MW-EP (raw)': ldplm_ep_raw_vals,\n",
    "    'LDPLM-MW-EP (filt)': ldplm_ep_filt_vals\n",
    "}, index=parameter_list)\n",
    "\n",
    "# Build Metrics DataFrame\n",
    "metrics = ['RMSE (Train)', 'RMSE (Test)', 'R2 (Train)', 'R2 (Test)', 'σ (dB)']\n",
    "metrics_values = {\n",
    "    'LDPLM-MW (raw)': [rmse_mw_raw_train, rmse_mw_raw_test, r2_mw_raw_train, r2_mw_raw_test, sigma_mw_raw],\n",
    "    'LDPLM-MW (filt)': [rmse_mw_filt_train, rmse_mw_filt_test, r2_mw_filt_train, r2_mw_filt_test, sigma_mw_filt],\n",
    "    'LDPLM-MW-EP (raw)': [rmse_ep_raw_train, rmse_ep_raw_test, r2_ep_raw_train, r2_ep_raw_test, sigma_ep_raw],\n",
    "    'LDPLM-MW-EP (filt)': [rmse_ep_filt_train, rmse_ep_filt_test, r2_ep_filt_train, r2_ep_filt_test, sigma_ep_filt]\n",
    "}\n",
    "metrics_df = pd.DataFrame(metrics_values, index=metrics)\n",
    "\n",
    "# Output the two tables\n",
    "print(\"\\n=== Table of Parameters to be Compared ===\\n\")\n",
    "display(params_comp_df)\n",
    "\n",
    "print(\"\\n=== Performance Metrics ===\\n\")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6692ce00-243d-4c3e-aede-f015bf02e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset of models we want to compare\n",
    "model_subset = ['LDPLM-MW (raw)', 'LDPLM-MW-EP (raw)', 'LDPLM-MW-EP (filt)']\n",
    "\n",
    "# Extract the relevant test metrics from your metrics_df\n",
    "rmse_test_values = metrics_df.loc['RMSE (Test)', model_subset]\n",
    "r2_test_values   = metrics_df.loc['R2 (Test)',   model_subset]\n",
    "sigma_values     = metrics_df.loc['σ (dB)',      model_subset]  # Shadowing\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(7, 2))\n",
    "\n",
    "# Define a color scheme for the three bars\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "# ----------------------\n",
    "# (a) RMSE(Test)\n",
    "# ----------------------\n",
    "bars_a = axs[0].bar(model_subset, rmse_test_values, color=colors)\n",
    "# axs[0].set_title('RMSE (Test)')\n",
    "axs[0].set_ylabel('RMSE (dB)')\n",
    "axs[0].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "axs[0].text(0.5, -0.05, '(a)', transform=axs[0].transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "# Label each bar in subplot (a) for the legend\n",
    "for bar, label in zip(bars_a, model_subset):\n",
    "    bar.set_label(label)\n",
    "\n",
    "# ----------------------\n",
    "# (b) R2(Test)\n",
    "# ----------------------\n",
    "axs[1].bar(model_subset, r2_test_values, color=colors)\n",
    "# axs[1].set_title('R² (Test)')\n",
    "axs[1].set_ylabel('R²')\n",
    "axs[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "axs[1].text(0.5, -0.05, '(b)', transform=axs[1].transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# ----------------------\n",
    "# (c) Shadowing (σ dB)\n",
    "# ----------------------\n",
    "axs[2].bar(model_subset, sigma_values, color=colors)\n",
    "# axs[2].set_title('Shadowing (σ dB)')\n",
    "axs[2].set_ylabel('Shadowing (σ dB)')\n",
    "axs[2].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "axs[2].text(0.5, -0.05, '(c)', transform=axs[2].transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# Create one combined legend below the subplots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.10), ncol=3)\n",
    "\n",
    "# Adjust layout to reduce the white gap at the bottom\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure at high resolution\n",
    "plt.savefig('../all_data_files/Localization/rmse_r2_comparison.png', dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9265a613-1e70-4e09-9c37-53be816e55e8",
   "metadata": {},
   "source": [
    "### Combined Plots (Raw & Filtered) and Residual Distribution Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b492cc49-44cb-4a83-8034-26aa906acc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute test residuals for raw and filtered models\n",
    "residuals_mw_test = y_test_raw - y_pred_mw_raw\n",
    "residuals_ep_test = y_test_raw - y_pred_ep_raw\n",
    "residuals_mw_test_filt = y_test_filt - y_pred_mw_filt\n",
    "residuals_ep_test_filt = y_test_filt - y_pred_ep_filt\n",
    "\n",
    "# Define plotting targets/predictions (raw & filtered)\n",
    "PL_test_mw = y_test_raw        # Raw target for MW & EP (identical)\n",
    "PL_test_ep = y_test_raw\n",
    "PL_pred_mw = y_pred_mw_raw     # Raw predictions\n",
    "PL_pred_ep = y_pred_ep_raw\n",
    "\n",
    "PL_test_mw_filt = y_test_filt  # Filtered targets for MW & EP (identical)\n",
    "PL_test_ep_filt = y_test_filt\n",
    "PL_pred_mw_filt = y_pred_mw_filt  # Filtered predictions\n",
    "PL_pred_ep_filt = y_pred_ep_filt\n",
    "\n",
    "# Define ideal fit line boundaries\n",
    "min_PL = min(PL_test_ep.min(), PL_test_mw.min())\n",
    "max_PL = max(PL_test_ep.max(), PL_test_mw.max())\n",
    "min_PL_filt = min(PL_test_ep_filt.min(), PL_test_mw_filt.min())\n",
    "max_PL_filt = max(PL_test_ep_filt.max(), PL_test_mw_filt.max())\n",
    "\n",
    "# Create a figure with 2 rows x 3 columns (Row 1: Raw, Row 2: Filtered)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# -------------------- Row 1: Raw Models --------------------\n",
    "# (a) Actual vs Predicted Path Loss\n",
    "ax = axes[0, 0]\n",
    "ax.scatter(PL_test_ep, PL_pred_ep, alpha=0.7, label='LDPLM-MW-EP', color='blue', zorder=2)\n",
    "ax.scatter(PL_test_mw, PL_pred_mw, alpha=0.7, label='LDPLM-MW', color='red', zorder=3)\n",
    "ax.plot([min_PL, max_PL], [min_PL, max_PL], 'k--', label='Ideal Fit', zorder=4)\n",
    "ax.set_xlabel('Actual Path Loss (dB)', fontsize=22)\n",
    "ax.set_ylabel('Predicted Path Loss (dB)', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper left')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(a)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "# (b) Residuals vs Predicted Path Loss\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(PL_pred_ep, residuals_ep_test, alpha=0.7, label='LDPLM-MW-EP', color='blue', zorder=2)\n",
    "ax.scatter(PL_pred_mw, residuals_mw_test, alpha=0.7, label='LDPLM-MW', color='red', zorder=3)\n",
    "ax.axhline(0, color='k', linestyle='--', label='Zero Residual', zorder=4)\n",
    "ax.set_xlabel('Predicted Path Loss (dB)', fontsize=22)\n",
    "ax.set_ylabel('Residuals (dB)', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(b)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "# (c) Histogram & KDE of Residuals\n",
    "ax = axes[0, 2]\n",
    "ax.hist(residuals_mw_test, bins=100, alpha=0.5, label='LDPLM-MW', color='green', edgecolor='k', density=True)\n",
    "ax.hist(residuals_ep_test, bins=100, alpha=0.5, label='LDPLM-MW-EP', color='red', edgecolor='k', density=True)\n",
    "sns.kdeplot(residuals_mw_test, color='green', bw_adjust=3, ax=ax, linewidth=5)\n",
    "sns.kdeplot(residuals_ep_test, color='red', bw_adjust=3, ax=ax, linewidth=5)\n",
    "ax.set_xlabel('Residuals (dB)', fontsize=22)\n",
    "ax.set_ylabel('Frequency', fontsize=22)\n",
    "ax.set_xlim(-30, 30)\n",
    "ax.legend(fontsize=20, loc='center right')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(c)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "# -------------------- Row 2: Filtered Models --------------------\n",
    "# (d) Actual vs Predicted Path Loss (Filtered)\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(PL_test_ep_filt, PL_pred_ep_filt, alpha=0.7, label='LDPLM-MW-EP (filt)', color='blue', zorder=2)\n",
    "ax.scatter(PL_test_mw_filt, PL_pred_mw_filt, alpha=0.7, label='LDPLM-MW (filt)', color='red', zorder=3)\n",
    "ax.plot([min_PL_filt, max_PL_filt], [min_PL_filt, max_PL_filt], 'k--', label='Ideal Fit', zorder=4)\n",
    "ax.set_xlabel('Actual Path Loss (dB)', fontsize=22)\n",
    "ax.set_ylabel('Predicted Path Loss (dB)', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper left')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(d)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "# (e) Residuals vs Predicted Path Loss (Filtered)\n",
    "ax = axes[1, 1]\n",
    "ax.scatter(PL_pred_ep_filt, residuals_ep_test_filt, alpha=0.7, label='LDPLM-MW-EP (filt)', color='blue', zorder=2)\n",
    "ax.scatter(PL_pred_mw_filt, residuals_mw_test_filt, alpha=0.7, label='LDPLM-MW (filt)', color='red', zorder=3)\n",
    "ax.axhline(0, color='k', linestyle='--', label='Zero Residual', zorder=4)\n",
    "ax.set_xlabel('Predicted Path Loss (dB)', fontsize=22)\n",
    "ax.set_ylabel('Residuals (dB)', fontsize=22)\n",
    "ax.legend(fontsize=22, loc='upper right')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(e)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "# (f) Histogram & KDE of Residuals (Filtered)\n",
    "ax = axes[1, 2]\n",
    "ax.hist(residuals_mw_test_filt, bins=100, alpha=0.5, label='LDPLM-MW (filt)', color='green', edgecolor='k', density=True)\n",
    "ax.hist(residuals_ep_test_filt, bins=100, alpha=0.5, label='LDPLM-MW-EP (filt)', color='red', edgecolor='k', density=True)\n",
    "sns.kdeplot(residuals_mw_test_filt, color='green', bw_adjust=3, ax=ax, linewidth=5)\n",
    "sns.kdeplot(residuals_ep_test_filt, color='red', bw_adjust=3, ax=ax, linewidth=5)\n",
    "ax.set_xlabel('Residuals (dB)', fontsize=22)\n",
    "ax.set_ylabel('Frequency', fontsize=22)\n",
    "ax.set_xlim(-30, 30)\n",
    "ax.legend(fontsize=20, loc='center right')\n",
    "ax.grid(True)\n",
    "ax.tick_params(axis='both', which='major', labelsize=22)\n",
    "ax.text(0.95, 0.05, '(f)', transform=ax.transAxes, fontsize=22, fontweight='bold', va='bottom', ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../all_data_files/All_Plots_as_Subplots_Kalman.png', dpi=1000)\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Residual Distribution Table (Test Data) --------------------\n",
    "resid_mean_mw      = round(np.mean(residuals_mw_test), 6)\n",
    "resid_skew_mw      = round(pd.Series(residuals_mw_test).skew(), 6)\n",
    "resid_mean_ep      = round(np.mean(residuals_ep_test), 6)\n",
    "resid_skew_ep      = round(pd.Series(residuals_ep_test).skew(), 6)\n",
    "resid_mean_mw_filt = round(np.mean(residuals_mw_test_filt), 6)\n",
    "resid_skew_mw_filt = round(pd.Series(residuals_mw_test_filt).skew(), 6)\n",
    "resid_mean_ep_filt = round(np.mean(residuals_ep_test_filt), 6)\n",
    "resid_skew_ep_filt = round(pd.Series(residuals_ep_test_filt).skew(), 6)\n",
    "\n",
    "resid_df = pd.DataFrame({\n",
    "    'Mean (dB)': [resid_mean_mw, resid_mean_mw_filt, resid_mean_ep, resid_mean_ep_filt],\n",
    "    'Skewness': [resid_skew_mw, resid_skew_mw_filt, resid_skew_ep, resid_skew_ep_filt]\n",
    "}, index=['LDPLM-MW (raw)', 'LDPLM-MW (filt)', 'LDPLM-MW-EP (raw)', 'LDPLM-MW-EP (filt)'])\n",
    "\n",
    "print(\"\\nResidual Distribution Values:\")\n",
    "display(resid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f8cfcd-e362-4c5d-876f-a2a0bc79b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a figure with 1 row x 2 columns\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "\n",
    "# ----------------------\n",
    "# (a) Raw Models - Labeled\n",
    "# ----------------------\n",
    "ax_left = axs[0]\n",
    "ax_left.scatter(PL_test_ep, PL_pred_ep, s=2, alpha=0.7, label='LDPLM-MW-EP', color='#1f77b4', zorder=2)\n",
    "ax_left.scatter(PL_test_mw, PL_pred_mw, s=2, alpha=0.7, label='LDPLM-MW', color='#ff7f0e', zorder=3)\n",
    "ax_left.plot([min_PL, max_PL], [min_PL, max_PL], 'k--', linewidth=2, label='Ideal Fit', zorder=4)\n",
    "ax_left.set_xlabel('Actual Path Loss (dB)', fontsize=14)\n",
    "ax_left.set_ylabel('Predicted PL (dB)', fontsize=14)\n",
    "ax_left.grid(True)\n",
    "ax_left.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax_left.text(0.5, -0.3, '(a)', transform=ax_left.transAxes,\n",
    "             fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# ----------------------\n",
    "# (b) Filtered Models - No Legend Labels\n",
    "# ----------------------\n",
    "ax_right = axs[1]\n",
    "ax_right.scatter(PL_test_ep_filt, PL_pred_ep_filt, s=2, alpha=0.7, label='_nolegend_', color='#1f77b4', zorder=2)\n",
    "ax_right.scatter(PL_test_mw_filt, PL_pred_mw_filt, s=2, alpha=0.7, label='_nolegend_', color='#ff7f0e', zorder=3)\n",
    "ax_right.plot([min_PL_filt, max_PL_filt], [min_PL_filt, max_PL_filt], 'k--', linewidth=2, label='_nolegend_', zorder=4)\n",
    "ax_right.set_xlabel('Actual Path Loss (dB)', fontsize=14)\n",
    "ax_right.set_ylabel('Predicted PL (dB)', fontsize=14)\n",
    "ax_right.grid(True)\n",
    "ax_right.tick_params(axis='both', which='major', labelsize=14)\n",
    "ax_right.text(0.5, -0.3, '(b)', transform=ax_right.transAxes,\n",
    "              fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# 2) Collect handles/labels from both subplots\n",
    "handles_left, labels_left = ax_left.get_legend_handles_labels()\n",
    "handles_right, labels_right = ax_right.get_legend_handles_labels()\n",
    "all_handles = handles_left + handles_right\n",
    "all_labels = labels_left + labels_right\n",
    "\n",
    "# 3) Create a single combined legend below the subplots\n",
    "fig.legend(all_handles, all_labels, loc='lower center', bbox_to_anchor=(0.5, 0.0), ncol=3, fontsize=12, markerscale=4)\n",
    "\n",
    "# 4) Final layout & save\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "plt.savefig('../all_data_files/Localization/Kalman_vs_Raw_Residuals.png', dpi=2000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4be92-b7a0-44d8-9208-6d8bdf0ffa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5))\n",
    "# Plot histograms for residuals with density normalization\n",
    "plt.hist(residuals_mw_test, bins=60, alpha=0.5, label='LDPLM-MW ', color='#1f77b4', density=True)\n",
    "plt.hist(residuals_ep_test, bins=60, alpha=0.5, label='LDPLM-MW-EP ', color='#ff7f0e', density=True)\n",
    "# Plot KDE curves for both residual distributions\n",
    "sns.kdeplot(residuals_mw_test, color='#1f77b4', bw_adjust=3, linewidth=2)\n",
    "sns.kdeplot(residuals_ep_test, color='#ff7f0e', bw_adjust=3, linewidth=2)\n",
    "# Set labels, title, and x-axis limits\n",
    "plt.xlabel('Residuals (dB)', fontsize=14)\n",
    "plt.ylabel('Density', fontsize=14)\n",
    "#plt.title('Residual Distribution (Raw Models)', fontsize=18)\n",
    "plt.xlim(-30, 30)\n",
    "plt.legend(fontsize=10, loc='upper right')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../all_data_files/Localization/residuals.png', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8f355-5ec9-4b6e-8722-2b7bfe2a104e",
   "metadata": {},
   "source": [
    "<p style=\"font-family: 'Courier New', Courier, monospace; font-size: 30px; font-weight: bold; color: blue;  text-align: center;\">\n",
    " Distance Estimation for Localization\n",
    "</p>\n",
    "\n",
    "### Distance Estimation: The Base Equations\n",
    "\n",
    "To estimate the distance $d$, we invert our main path loss models. This provides a direct means to compute the distance from the observed path loss values. The derivations are kept succinct to maintain clarity.\n",
    "\n",
    "**Model A (LDPLM-MW):**\n",
    "\n",
    "<div style=\"font-size: 150%;\">\n",
    "$$\n",
    "d = 10^{\\frac{PL - PL(d_0) - \\left(W_c L_c + W_w L_w\\right)}{10\\,n}},\n",
    "$$\n",
    "\n",
    "</div>\n",
    "\n",
    "**Model B (LDPLM-MW-EP):**\n",
    "\n",
    "<div style=\"font-size: 150%;\">\n",
    "\n",
    "$$\n",
    "d = 10^{\\frac{PL - PL(d_0) - 20\\,\\log_{10}(f) - \\left(W_c L_c + W_w L_w\\right) - \\sum_{j=1}^{5} \\theta_j\\,E_j - k_{snr}\\,snr}{10\\,n}}.\n",
    "$$\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "These inverted equations allow us to compute the distance from the measured path loss while accounting for both structural losses (from walls) and environmental factors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e563d981-c676-4d79-aa1c-67b12cceff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Define Distance Inversion Functions for distance estimation\n",
    "# ----------------------------\n",
    "def estimate_distance_modelA(PL, PL_d0, n, L_c, L_w, W_c, W_w):\n",
    "    # LDPLM-MW: Model A\n",
    "    # PL = PL(d0) + 10*n*log10(d) + (W_c*L_c + W_w*L_w) + ε\n",
    "    return 10 ** ((PL - PL_d0 - (W_c * L_c + W_w * L_w)) / (10 * n))\n",
    "\n",
    "def estimate_distance_modelB(PL, PL_d0, n, L_c, L_w, f, theta_E, E_matrix, k_snr, SNR, W_c, W_w):\n",
    "    # LDPLM-MW-EP: Model B\n",
    "    # PL = PL(d0) + 10*n*log10(d) + 20*log10(f) + (W_c*L_c + W_w*L_w)\n",
    "    #      + (θ1*E1 + ... + θ5*E5) + k_SNR*SNR + ε\n",
    "    env_term = np.dot(theta_E, E_matrix)  # E_matrix shape: (5, number_of_samples)\n",
    "    return 10 ** ((PL - PL_d0 - 20*np.log10(f) - (W_c * L_c + W_w * L_w) - env_term - k_snr * SNR) / (10 * n))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Prepare Environmental Data; particularly for Model B\n",
    "# ------------------------------------------------------------\n",
    "E_matrix_test = np.array([\n",
    "    test_df['co2'].values,\n",
    "    test_df['humidity'].values,\n",
    "    test_df['pm25'].values,\n",
    "    test_df['pressure'].values,\n",
    "    test_df['temperature'].values\n",
    "])\n",
    "f_test   = test_df['frequency'].values\n",
    "W_c_test = test_df['c_walls'].values\n",
    "W_w_test = test_df['w_walls'].values\n",
    "SNR_test = test_df['snr'].values\n",
    "\n",
    "# ----------------------------\n",
    "# Compute Distance Estimates (using full PL)\n",
    "# ----------------------------\n",
    "# Model A (LDPLM-MW)\n",
    "d_A_raw = estimate_distance_modelA(\n",
    "    PL = test_df['exp_pl'].values,\n",
    "    PL_d0 = popt_mw_raw[0],\n",
    "    n = popt_mw_raw[1],\n",
    "    L_c = popt_mw_raw[2],\n",
    "    L_w = popt_mw_raw[3],\n",
    "    W_c = W_c_test,\n",
    "    W_w = W_w_test\n",
    ")\n",
    "d_A_filt = estimate_distance_modelA(\n",
    "    PL = test_df['exp_pl_filtered'].values,\n",
    "    PL_d0 = popt_mw_filt[0],\n",
    "    n = popt_mw_filt[1],\n",
    "    L_c = popt_mw_filt[2],\n",
    "    L_w = popt_mw_filt[3],\n",
    "    W_c = W_c_test,\n",
    "    W_w = W_w_test\n",
    ")\n",
    "\n",
    "# Model B (LDPLM-MW-EP)\n",
    "theta_E_raw  = popt_ep_raw[4:9]\n",
    "theta_E_filt = popt_ep_filt[4:9]\n",
    "\n",
    "d_B_raw = estimate_distance_modelB(\n",
    "    PL = test_df['exp_pl'].values,\n",
    "    PL_d0 = popt_ep_raw[0],\n",
    "    n = popt_ep_raw[1],\n",
    "    L_c = popt_ep_raw[2],\n",
    "    L_w = popt_ep_raw[3],\n",
    "    f = f_test,\n",
    "    theta_E = theta_E_raw,\n",
    "    E_matrix = E_matrix_test,\n",
    "    k_snr = popt_ep_raw[9],\n",
    "    SNR = SNR_test,\n",
    "    W_c = W_c_test,\n",
    "    W_w = W_w_test\n",
    ")\n",
    "d_B_filt = estimate_distance_modelB(\n",
    "    PL = test_df['exp_pl_filtered'].values,\n",
    "    PL_d0 = popt_ep_filt[0],\n",
    "    n = popt_ep_filt[1],\n",
    "    L_c = popt_ep_filt[2],\n",
    "    L_w = popt_ep_filt[3],\n",
    "    f = f_test,\n",
    "    theta_E = theta_E_filt,\n",
    "    E_matrix = E_matrix_test,\n",
    "    k_snr = popt_ep_filt[9],\n",
    "    SNR = SNR_test,\n",
    "    W_c = W_c_test,\n",
    "    W_w = W_w_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2339b-a514-49cb-bad3-3c8e8c29d01b",
   "metadata": {},
   "source": [
    "### Analysis Metrics for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dfde8f-89ff-4c22-ae2d-dc8e17a604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------\n",
    "# Compute Metrics for Model Comaprison\n",
    "# ------------------------------------------------\n",
    "def compute_metrics(true, pred):\n",
    "    mae = mean_absolute_error(true, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(true, pred))\n",
    "    r2 = r2_score(true, pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "true_distance = test_df['distance'].values\n",
    "\n",
    "metrics_neglected = {\n",
    "    'Model A Raw': compute_metrics(true_distance, d_A_raw),\n",
    "    'Model A Filt': compute_metrics(true_distance, d_A_filt),\n",
    "    'Model B Raw': compute_metrics(true_distance, d_B_raw),\n",
    "    'Model B Filt': compute_metrics(true_distance, d_B_filt)\n",
    "}\n",
    "\n",
    "metrics_df_neglected = pd.DataFrame(metrics_neglected, index=['MAE', 'RMSE', 'R²'])\n",
    "print(\"\\n=== Distance Estimation Metrics ===\\n\")\n",
    "display(metrics_df_neglected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149f7100-5c40-49e6-8607-d6f5d512cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the subset of models to compare\n",
    "model_subset = ['Model A Raw', 'Model B Raw', 'Model B Filt']\n",
    "\n",
    "# Extract RMSE and MAE values from your metrics dataframe\n",
    "rmse_values = metrics_df_neglected.loc['RMSE', model_subset]\n",
    "mae_values  = metrics_df_neglected.loc['MAE', model_subset]\n",
    "\n",
    "# Create subplots for RMSE and MAE\n",
    "fig, axs = plt.subplots(1, 2, figsize=(5, 2))\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "# (a) RMSE plot\n",
    "bars_a = axs[0].bar(model_subset, rmse_values, color=colors)\n",
    "axs[0].set_ylabel('RMSE (m)')\n",
    "axs[0].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "axs[0].text(0.5, -0.1, '(a)', transform=axs[0].transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center')\n",
    "# Label each bar for the common legend\n",
    "for bar, label in zip(bars_a, model_subset):\n",
    "    bar.set_label(label)\n",
    "\n",
    "# (b) MAE plot\n",
    "axs[1].bar(model_subset, mae_values, color=colors)\n",
    "axs[1].set_ylabel('MAE (m)')\n",
    "axs[1].tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "axs[1].text(0.5, -0.1, '(b)', transform=axs[1].transAxes,\n",
    "            fontsize=12, fontweight='bold', ha='center')\n",
    "\n",
    "# Create a common legend below the subplots\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=3)\n",
    "\n",
    "plt.subplots_adjust(bottom=0.25)\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.savefig('../all_data_files/Localization/distance_rmse_mae_comparison.png', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbf4d10-9843-43d3-ba6b-174687aaafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------\n",
    "# Compute absolute errors and CDF for both models\n",
    "# ----------------------------------------------------\n",
    "\n",
    "def compute_cdf(errors, bins=100):\n",
    "    hist_vals, bin_edges = np.histogram(errors, bins=bins, density=True)\n",
    "    cdf_vals = np.cumsum(hist_vals * np.diff(bin_edges))\n",
    "    return bin_edges[1:], cdf_vals\n",
    "\n",
    "error_A_raw  = np.abs(true_distance - d_A_raw)\n",
    "error_A_filt = np.abs(true_distance - d_A_filt)\n",
    "error_B_raw  = np.abs(true_distance - d_B_raw)\n",
    "error_B_filt = np.abs(true_distance - d_B_filt)\n",
    "\n",
    "x_A_raw,  cdf_A_raw  = compute_cdf(error_A_raw)\n",
    "x_A_filt, cdf_A_filt = compute_cdf(error_A_filt)\n",
    "x_B_raw,  cdf_B_raw  = compute_cdf(error_B_raw)\n",
    "x_B_filt, cdf_B_filt = compute_cdf(error_B_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd04386-0c92-4df3-940a-1e33025bfe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Scatter Plots (2x1 for estimated vs actual distance)\n",
    "# -------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "\n",
    "# Define a jitter value for visual separation\n",
    "jitter = 0.3\n",
    "\n",
    "def plot_scatter(ax, actual, pred_A, pred_B, title):\n",
    "    # Add jitter to actual distances for Model A and Model B\n",
    "    ax.scatter(actual + jitter, pred_A, alpha=0.6, label='LDPLM-MW', color='blue')\n",
    "    ax.scatter(actual - jitter, pred_B, alpha=0.6, label='LDPLM-MW-EP', color='green')\n",
    "    ax.plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'k--', label='Ideal')\n",
    "    ax.set_xlabel('Actual Distance (m)', fontsize=12)\n",
    "    ax.set_ylabel('Estimated Distance (m)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.grid(True)\n",
    "\n",
    "# Plot scatter for Raw RSSI and Filtered RSSI\n",
    "plot_scatter(axes[0], true_distance, d_A_raw, d_B_raw, 'Raw RSSI')\n",
    "plot_scatter(axes[1], true_distance, d_A_filt, d_B_filt, 'Filtered RSSI')\n",
    "\n",
    "# Add subplot labels (a) and (b) below each subplot\n",
    "axes[0].text(0.5, -0.3, '(a)', transform=axes[0].transAxes,\n",
    "             fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "axes[1].text(0.5, -0.3, '(b)', transform=axes[1].transAxes,\n",
    "             fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# Collect handles/labels from both subplots\n",
    "handles_a, labels_a = axes[0].get_legend_handles_labels()\n",
    "handles_b, labels_b = axes[1].get_legend_handles_labels()\n",
    "all_handles = handles_a + handles_b\n",
    "all_labels = labels_a + labels_b\n",
    "\n",
    "# Remove duplicate legend entries while preserving order\n",
    "seen = {}\n",
    "unique_handles = []\n",
    "unique_labels = []\n",
    "for h, lbl in zip(all_handles, all_labels):\n",
    "    if lbl not in seen:\n",
    "        unique_handles.append(h)\n",
    "        unique_labels.append(lbl)\n",
    "        seen[lbl] = True\n",
    "\n",
    "# Create a single combined legend below the subplots\n",
    "fig.legend(unique_handles, unique_labels, loc='lower center', bbox_to_anchor=(0.5, 0.0), ncol=3, fontsize=12)\n",
    "\n",
    "# Adjust layout to include legend space and save the figure\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 1])\n",
    "plt.savefig('../all_data_files/Localization/distance_scatter.png', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31182732-46dc-4fb0-b940-2ae38d56de5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots (1 row, 2 columns) for residuals vs actual distance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3.5))\n",
    "\n",
    "# Compute residuals for Raw and Filtered RSSI\n",
    "resid_A_raw  = true_distance - d_A_raw\n",
    "resid_B_raw  = true_distance - d_B_raw\n",
    "resid_A_filt = true_distance - d_A_filt\n",
    "resid_B_filt = true_distance - d_B_filt\n",
    "\n",
    "# Define function to plot residuals with jitter\n",
    "def plot_residuals(ax, actual, resid_A, resid_B, title, jitter=0.3):\n",
    "    # Add jitter to actual distances for Model A and Model B residuals\n",
    "    ax.scatter(actual + jitter, resid_A, alpha=0.6, s=20, color='blue', marker='o', label='LDPLM-MW')\n",
    "    ax.scatter(actual - jitter, resid_B, alpha=0.6, s=20, color='green', marker='^', label='LDPLM-MW-EP')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1, label='Zero Error')\n",
    "    ax.set_xlabel('Actual Distance (m)', fontsize=12)\n",
    "    ax.set_ylabel('Residual (m)', fontsize=12)\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    ax.grid(True)\n",
    "\n",
    "# Plot residuals for Raw and Filtered RSSI\n",
    "plot_residuals(axes[0], true_distance, resid_A_raw, resid_B_raw, 'Raw RSSI')\n",
    "plot_residuals(axes[1], true_distance, resid_A_filt, resid_B_filt, 'Filtered RSSI')\n",
    "\n",
    "# Add subplot labels (a) and (b) below each subplot\n",
    "axes[0].text(0.5, -0.3, '(a)', transform=axes[0].transAxes,\n",
    "             fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "axes[1].text(0.5, -0.3, '(b)', transform=axes[1].transAxes,\n",
    "             fontsize=12, fontweight='bold', ha='center', va='top')\n",
    "\n",
    "# Collect handles and labels from both subplots\n",
    "handles_a, labels_a = axes[0].get_legend_handles_labels()\n",
    "handles_b, labels_b = axes[1].get_legend_handles_labels()\n",
    "all_handles = handles_a + handles_b\n",
    "all_labels = labels_a + labels_b\n",
    "\n",
    "# Remove duplicate legend entries while preserving order\n",
    "seen = {}\n",
    "unique_handles = []\n",
    "unique_labels = []\n",
    "for h, lbl in zip(all_handles, all_labels):\n",
    "    if lbl not in seen:\n",
    "        unique_handles.append(h)\n",
    "        unique_labels.append(lbl)\n",
    "        seen[lbl] = True\n",
    "\n",
    "# Create a single combined legend below the subplots\n",
    "fig.legend(unique_handles, unique_labels, loc='lower center', bbox_to_anchor=(0.5, 0.0), ncol=3, fontsize=12)\n",
    "\n",
    "# Adjust layout to include space for the legend\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e116a47-d99c-48ef-8c43-c1da526f82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# CDF Plots (1x1 for CDF of mean absolute errors)\n",
    "# ----------------------------\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "\n",
    "plt.plot(x_A_raw,  cdf_A_raw,  label='LDPLM-MW Raw',  color='blue',   marker='o', markersize=3)\n",
    "#plt.plot(x_A_filt, cdf_A_filt, label='LDPLM-MW Filt', color='green',  marker='^', markersize=3)\n",
    "plt.plot(x_B_raw,  cdf_B_raw,  label='LDPLM-MW-EP Raw',  color='purple', marker='o', markersize=3)\n",
    "plt.plot(x_B_filt, cdf_B_filt, label='LDPLM-MW-EP Filt', color='cyan',   marker='^', markersize=3)\n",
    "#plt.title('CDF of MEA', fontsize=14)\n",
    "plt.xlabel('Absolute Error (m)', fontsize=12)\n",
    "plt.ylabel('Cumulative Probability', fontsize=12)\n",
    "plt.xlim(0, 50)\n",
    "plt.ylim(0, 1)\n",
    "plt.grid(True)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../all_data_files/Localization/cdf_errors.png', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c52a3-61e6-4a29-bed1-a587340c6113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Relative Errors (%) explicitly per device\n",
    "\n",
    "# Combine necessary data into one DataFrame\n",
    "error_df = test_df[['device_id', 'distance']].copy()\n",
    "\n",
    "# Calculate relative errors (%)\n",
    "error_df['raw_error_A'] = 100 * np.abs(true_distance - d_A_raw) / true_distance\n",
    "error_df['filtered_error_A'] = 100 * np.abs(true_distance - d_A_filt) / true_distance\n",
    "error_df['raw_error_B'] = 100 * np.abs(true_distance - d_B_raw) / true_distance\n",
    "error_df['filtered_error_B'] = 100 * np.abs(true_distance - d_B_filt) / true_distance\n",
    "\n",
    "error_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14858e7c-dd43-4df4-8f91-2192f394b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot visualization for relative errors per device (with IQR filtering)\n",
    "\n",
    "# Define the IQR filtering function\n",
    "def filter_outliers_iqr(df, cols, multiplier=1.5):\n",
    "    filtered_df = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        filtered_df = filtered_df[(filtered_df[col] >= lower_bound) & (filtered_df[col] <= upper_bound)]\n",
    "    return filtered_df\n",
    "\n",
    "# Assume 'error_df' is your existing DataFrame\n",
    "cols_to_check = ['raw_error_A', 'filtered_error_A', 'raw_error_B', 'filtered_error_B']\n",
    "iqr_filtered_df = filter_outliers_iqr(error_df, cols_to_check)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "# Sort devices by mean distance\n",
    "devices_sorted = iqr_filtered_df.groupby('device_id')['distance'].mean().sort_values().index\n",
    "positions = np.arange(len(devices_sorted))\n",
    "box_width = 0.18\n",
    "\n",
    "colors = ['lightblue', 'blue', 'lightgreen', 'green']\n",
    "\n",
    "# Plot boxplots for each device\n",
    "for idx, device in enumerate(devices_sorted):\n",
    "    device_data = iqr_filtered_df[iqr_filtered_df['device_id'] == device]\n",
    "\n",
    "    data_to_plot = [\n",
    "        device_data['raw_error_A'],\n",
    "        device_data['filtered_error_A'],\n",
    "        device_data['raw_error_B'],\n",
    "        device_data['filtered_error_B']\n",
    "    ]\n",
    "\n",
    "    pos = positions[idx] + np.array([-1.5, -0.5, 0.5, 1.5]) * box_width\n",
    "    bp = ax.boxplot(data_to_plot, positions=pos, widths=box_width, patch_artist=True,\n",
    "                    medianprops=dict(color='black'))\n",
    "\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "# Legend: \"Models:\" on the same line as the first label\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, facecolor=color) for color in colors]\n",
    "labels = ['Models: Raw A', 'Filtered A', 'Raw B', 'Filtered B']\n",
    "ax.legend(handles, labels, fontsize=10, loc='upper center',\n",
    "          bbox_to_anchor=(0.5, -0.25), ncol=4)\n",
    "\n",
    "# X-axis labels: \"ED1 (8 m)\", \"ED2 (10 m)\", etc.\n",
    "device_labels = [\n",
    "    f'ED{idx+1} ({int(iqr_filtered_df[iqr_filtered_df[\"device_id\"] == device][\"distance\"].iloc[0])} m)'\n",
    "    for idx, device in enumerate(devices_sorted)\n",
    "]\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(device_labels, fontsize=10)\n",
    "\n",
    "# More y-axis ticks: set major tick spacing to 5 (adjust as needed)\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(18))\n",
    "\n",
    "\n",
    "ax.set_ylabel('Relative Error (%)', fontsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout so legend has room below the plot\n",
    "plt.tight_layout(rect=[0, 0.15, 1, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa3eef-c8d3-4f6b-beaf-e4bc0e3d87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean relative errors per device after robust IQR filtering\n",
    "mean_errors_per_device = iqr_filtered_df.groupby('device_id')[cols_to_check].mean().round(2)\n",
    "\n",
    "# Compute overall mean relative errors across all devices\n",
    "overall_mean_errors = iqr_filtered_df[cols_to_check].mean().round(2)\n",
    "\n",
    "# Display results \n",
    "print(\"\\nMean Relative Errors (%) per Device:\\n\")\n",
    "display(mean_errors_per_device)\n",
    "print(\"\\nOverall Mean Relative Errors (%):\\n\")\n",
    "print(overall_mean_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26203c6-ce84-4494-bbc5-764cbf024d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot visualization for relative errors per device (with IQR filtering)\n",
    "\n",
    "# Define the IQR filtering function\n",
    "\n",
    "def filter_outliers_iqr(df, cols, multiplier=1.5):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing error columns to be filtered.\n",
    "    cols : list of str\n",
    "        The column names in `df` on which to apply the IQR filtering.\n",
    "    multiplier : float, optional (default=1.5)\n",
    "        The multiplier for the IQR to determine outlier boundaries.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered_df : pd.DataFrame\n",
    "        A copy of the input DataFrame with outliers removed based on IQR filtering.\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        filtered_df = filtered_df[(filtered_df[col] >= lower_bound) & (filtered_df[col] <= upper_bound)]\n",
    "    return filtered_df\n",
    "\n",
    "# Apply filtering to relative_error_df\n",
    "cols_to_check = ['raw_error_A', 'filtered_error_A', 'raw_error_B', 'filtered_error_B']\n",
    "robust_relative_error_df = filter_outliers_iqr(error_df, cols_to_check)\n",
    "\n",
    "# Create one row of 6 subplots\n",
    "fig, axes = plt.subplots(1, 6, figsize=(8, 2.4), sharey=True)\n",
    "\n",
    "# Sort devices by mean distance\n",
    "devices_sorted = robust_relative_error_df.groupby('device_id')['distance'].mean().sort_values().index\n",
    "\n",
    "# Loop through each device and plot 4 boxplots (Raw A, Filtered A, Raw B, Filtered B)\n",
    "for idx, device in enumerate(devices_sorted):\n",
    "    device_data = robust_relative_error_df[robust_relative_error_df['device_id'] == device]\n",
    "    \n",
    "    data_to_plot = [\n",
    "        device_data['raw_error_A'],\n",
    "        device_data['filtered_error_A'],\n",
    "        device_data['raw_error_B'],\n",
    "        device_data['filtered_error_B']\n",
    "    ]\n",
    "    \n",
    "    bp = axes[idx].boxplot(\n",
    "        data_to_plot,\n",
    "        patch_artist=True,\n",
    "        medianprops=dict(color='black')\n",
    "    )\n",
    "    \n",
    "    # Color the boxes (two for Model A, two for Model B)\n",
    "    box_colors = ['lightblue', 'blue', 'lightgreen', 'green']\n",
    "    for patch, color in zip(bp['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    # Remove numeric x-tick labels (1, 2, 3, 4) so only the device label remains\n",
    "    axes[idx].set_xticks([])\n",
    "    axes[idx].set_xticklabels([])\n",
    "\n",
    "    # Set device label as the x-axis label\n",
    "    distance_val = int(device_data[\"distance\"].iloc[0])\n",
    "    axes[idx].set_xlabel(f'ED{idx+1} ({distance_val} m)', fontsize=10)\n",
    "    \n",
    "    # Only the first (leftmost) subplot gets a y-axis label to avoid repetition\n",
    "    if idx == 0:\n",
    "        axes[idx].set_ylabel('Relative Error (%)')\n",
    "    else:\n",
    "        axes[idx].set_ylabel('')\n",
    "    \n",
    "    # Grid for better readability\n",
    "    axes[idx].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Create a single legend for the entire figure\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, facecolor=color) for color in box_colors]\n",
    "labels = ['Models: Raw A', 'Filtered A', 'Raw B', 'Filtered B']\n",
    "fig.legend(handles, labels, fontsize=10, loc='upper center', bbox_to_anchor=(0.5, 0.1), ncol=4)\n",
    "\n",
    "# Increase y-axis tick density if desired\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(18))\n",
    "\n",
    "# Adjust layout to fit legend and labels\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cfd817-d0a0-49e1-a262-ed230d8d2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot visualization for relative errors per device (with IQR filtering)\n",
    "\n",
    "# Define the IQR filtering function\n",
    "def filter_outliers_iqr(df, cols, multiplier=1.5):\n",
    "    \"\"\"    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The input DataFrame containing error columns to be filtered.\n",
    "    cols : list of str\n",
    "        The column names in `df` on which to apply the IQR filtering.\n",
    "    multiplier : float, optional (default=1.5)\n",
    "        The multiplier for the IQR to determine outlier boundaries.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    filtered_df : pd.DataFrame\n",
    "        A copy of the input DataFrame with outliers removed based on IQR filtering.\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - multiplier * IQR\n",
    "        upper_bound = Q3 + multiplier * IQR\n",
    "        filtered_df = filtered_df[(filtered_df[col] >= lower_bound) & (filtered_df[col] <= upper_bound)]\n",
    "    return filtered_df\n",
    "\n",
    "# Apply filtering to relative_error_df\n",
    "cols_to_check = ['raw_error_A', 'filtered_error_A', 'raw_error_B', 'filtered_error_B']\n",
    "robust_relative_error_df = filter_outliers_iqr(error_df, cols_to_check)\n",
    "\n",
    "# Create one row of 6 subplots\n",
    "fig, axes = plt.subplots(1, 6, figsize=(8, 2.4), sharey=True)\n",
    "\n",
    "# Sort devices by mean distance\n",
    "devices_sorted = robust_relative_error_df.groupby('device_id')['distance'].mean().sort_values().index\n",
    "\n",
    "# Loop through each device and plot 3 boxplots (Raw A, Raw B, Filtered B)\n",
    "for idx, device in enumerate(devices_sorted):\n",
    "    device_data = robust_relative_error_df[robust_relative_error_df['device_id'] == device]\n",
    "    \n",
    "    data_to_plot = [\n",
    "        device_data['raw_error_A'],       # Raw A\n",
    "        device_data['raw_error_B'],       # Raw B\n",
    "        device_data['filtered_error_B']   # Filtered B\n",
    "    ]\n",
    "    \n",
    "    bp = axes[idx].boxplot(\n",
    "        data_to_plot,\n",
    "        patch_artist=True,\n",
    "        medianprops=dict(color='black'),\n",
    "        widths=0.7\n",
    "    )\n",
    "    \n",
    "    # Color the boxes (Raw A in lightblue, Raw B in lightgreen, Filtered B in green)\n",
    "    #box_colors = ['lightblue', 'lightgreen', 'green']\n",
    "    box_colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    for patch, color in zip(bp['boxes'], box_colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    # Remove numeric x-tick labels (1, 2, 3) so only the device label remains\n",
    "    axes[idx].set_xticks([])\n",
    "    axes[idx].set_xticklabels([])\n",
    "\n",
    "    # Set device label as the x-axis label\n",
    "    distance_val = int(device_data[\"distance\"].iloc[0])\n",
    "    axes[idx].set_xlabel(f'ED{idx+1} ({distance_val} m)', fontsize=10)\n",
    "    \n",
    "    # Only the first (leftmost) subplot gets a y-axis label to avoid repetition\n",
    "    if idx == 0:\n",
    "        axes[idx].set_ylabel('Relative Error (%)')\n",
    "    else:\n",
    "        axes[idx].set_ylabel('')\n",
    "    \n",
    "    # Grid for better readability\n",
    "    axes[idx].grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Create a single legend for the entire figure\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, facecolor=color) for color in box_colors]\n",
    "labels = ['Models: Raw A', 'Raw B', 'Filtered B']  # Removed \"Filtered A\"\n",
    "fig.legend(handles, labels, fontsize=10, loc='upper center', bbox_to_anchor=(0.5, 0.1), ncol=3)\n",
    "\n",
    "# Increase y-axis tick density if desired\n",
    "for ax in axes:\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(18))\n",
    "\n",
    "# Adjust layout to fit legend and labels\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "\n",
    "plt.savefig('../all_data_files/Localization/relative_errors_boxplots_per_device.png', dpi=1000, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kalman_env)",
   "language": "python",
   "name": "kalman_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
